<!DOCTYPE html>
<html lang="en">
	<head>
	<meta charset="utf-8">
	<title>std.parallelism - Phobos documentation</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author" content="">

	<!-- styles -->
	<link href="bootDoc/assets/css/bootstrap.css" rel="stylesheet">
	<style type="text/css">
		body {
		padding-top: 60px;
		padding-bottom: 40px;
		}
		.sidebar-nav {
		padding: 9px 0;
		}
	</style>
	<link href="bootDoc/assets/css/bootstrap-responsive.css" rel="stylesheet">
	<link href="bootDoc/bootdoc.css" rel="stylesheet">

	<!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
	<!--[if lt IE 9]>
		<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<!-- fav and touch icons -->
	<link rel="shortcut icon" href="favicon.ico">
	<link rel="apple-touch-icon-precomposed" sizes="114x114" href="bootDoc/assets/ico/apple-touch-icon-114-precomposed.png">
	<link rel="apple-touch-icon-precomposed" sizes="72x72" href="bootDoc/assets/ico/apple-touch-icon-72-precomposed.png">
	<link rel="apple-touch-icon-precomposed" href="bootDoc/assets/ico/apple-touch-icon-57-precomposed.png">
	
	<!-- Introduce DDoc settings required by JavaScript -->
	<script type="text/javascript">
		var Title = 'std.parallelism';
		var SourceRepository = 'https://github.com/D-Programming-Language/phobos/tree/master';
		var Modules = [
			
	"index",
	"etc.c.curl",
	"etc.c.sqlite3",
	"etc.c.zlib",
	"std.algorithm",
	"std.array",
	"std.ascii",
	"std.base64",
	"std.bigint",
	"std.bind",
	"std.bitmanip",
	"std.c.fenv",
	"std.c.locale",
	"std.c.math",
	"std.c.process",
	"std.c.stdarg",
	"std.c.stddef",
	"std.c.stdio",
	"std.c.stdlib",
	"std.c.string",
	"std.c.time",
	"std.c.wcharh",
	"std.c.windows.com",
	"std.c.windows.stat",
	"std.c.windows.windows",
	"std.c.windows.winsock",
	"std.compiler",
	"std.complex",
	"std.concurrency",
	"std.container",
	"std.conv",
	"std.cpuid",
	"std.cstream",
	"std.csv",
	"std.datetime",
	"std.demangle",
	"std.encoding",
	"std.exception",
	"std.file",
	"std.format",
	"std.functional",
	"std.getopt",
	"std.internal.math.biguintcore",
	"std.internal.math.biguintnoasm",
	"std.internal.math.biguintx86",
	"std.internal.math.errorfunction",
	"std.internal.math.gammafunction",
	"std.internal.processinit",
	"std.internal.uni",
	"std.internal.uni_tab",
	"std.internal.windows.advapi32",
	"std.json",
	"std.loader",
	"std.math",
	"std.mathspecial",
	"std.md5",
	"std.metastrings",
	"std.mmfile",
	"std.net.curl",
	"std.net.isemail",
	"std.numeric",
	"std.outbuffer",
	"std.parallelism",
	"std.path",
	"std.perf",
	"std.process",
	"std.random",
	"std.range",
	"std.regex",
	"std.regexp",
	"std.signals",
	"std.socket",
	"std.socketstream",
	"std.stdarg",
	"std.stdint",
	"std.stdio",
	"std.stdiobase",
	"std.stream",
	"std.string",
	"std.syserror",
	"std.system",
	"std.traits",
	"std.typecons",
	"std.typetuple",
	"std.uni",
	"std.uri",
	"std.utf",
	"std.variant",
	"std.windows.charset",
	"std.windows.iunknown",
	"std.windows.registry",
	"std.windows.syserror",
	"std.xml",
	"std.zip",
	"std.zlib",
	"unittest",
		];
	</script>
	
	<style type="text/css">
		.ddoc-icon-variable { background-image: url('bootDoc/ddoc-icons/var.png'); }
		.ddoc-icon-function { background-image: url('bootDoc/ddoc-icons/func.png'); }
		.ddoc-icon-property { background-image: url('bootDoc/ddoc-icons/property.png'); }
		.ddoc-icon-struct { background-image: url('bootDoc/ddoc-icons/struct.png'); }
		.ddoc-icon-class { background-image: url('bootDoc/ddoc-icons/class.png'); }
		.ddoc-icon-enum { background-image: url('bootDoc/ddoc-icons/enum.png'); }
		.ddoc-icon-template { background-image: url('bootDoc/ddoc-icons/template.png'); }
	</style>
	</head>

	<body>
	<div class="navbar navbar-fixed-top">
		<div class="navbar-inner">
			<div class="container-fluid">
				<a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</a>
				<a class="brand" href="index.html">Phobos</a>
				<div class="nav-collapse">
					<ul class="nav">
						<li class="active"><a href="index.html">Reference</a></li>
					</ul>
					
					<form id="gotosymbol" class="navbar-search pull-left hidden">
						<input type="text" class="search-query" placeholder="Goto symbol in std.parallelism" data-provide="typeahead" data-items="4">
					</form>
					
					<p class="navbar-text pull-right"><a href="https://github.com/D-Programming-Language/phobos">Github Page</a></p>
				</div><!--/.nav-collapse -->
			</div>
		</div>
	</div>

	<div class="container-fluid">
		<div class="row-fluid">
			<div class="span2">
				<div class="well sidebar-nav">
				<ul class="nav nav-list">
					<li id="module-list" class="nav-header">Modules<li>
					<li id="symbol-list" class="nav-header hidden">std.parallelism</li>
				</ul>
				</div><!--/.well -->
			</div><!--/span-->
			
			<div class="span10">
				<div class="row-fluid">
					<div class="span11">
						<ul id="module-breadcrumb" class="breadcrumb">
							<noscript><h1>std.parallelism</h1></noscript>
						</ul>
						
					</div>
					<div class="span1 offset11">
						<a href="index.html"><img src="dlogo-small.png" alt="The D Programming Language"/></a>
					</div>
				</div>
				<div id="declaration-list">
					<!-- Generated by Ddoc from phobos\std\parallelism.d -->
<p><span class="inlinecode">std.parallelism</span> implements high-level primitives for SMP parallelism.
These include parallel foreach, parallel reduce, parallel eager map, pipelining
and future/promise parallelism.  <span class="inlinecode">std.parallelism</span> is recommended when the
same operation is to be executed in parallel on different data, or when a
function is to be executed in a background thread and its result returned to a
well-defined main thread.  For communication between arbitrary threads, see
<span class="inlinecode">std.concurrency</span>.
</p>

<p><span class="inlinecode">std.parallelism</span> is based on the concept of a <span class="inlinecode">Task</span>.  A <span class="inlinecode">Task</span> is an
object that represents the fundamental unit of work in this library and may be
executed in parallel with any other <span class="inlinecode">Task</span>.  Using <span class="inlinecode">Task</span>
directly allows programming with a future/promise paradigm.  All other
supported parallelism paradigms (parallel foreach, map, reduce, pipelining)
represent an additional level of abstraction over <span class="inlinecode">Task</span>.  They
automatically create one or more <span class="inlinecode">Task</span> objects, or closely related types
that are conceptually identical but not part of the public API.
<br><br>

After creation, a <span class="inlinecode">Task</span> may be executed in a new thread, or submitted
to a <span class="inlinecode">TaskPool</span> for execution.  A <span class="inlinecode">TaskPool</span> encapsulates a task queue
and its worker threads.  Its purpose is to efficiently map a large
number of <span class="inlinecode">Task</span>s onto a smaller number of threads.  A task queue is a
FIFO queue of <span class="inlinecode">Task</span> objects that have been submitted to the
<span class="inlinecode">TaskPool</span> and are awaiting execution.  A worker thread is a thread that
is associated with exactly one task queue.  It executes the <span class="inlinecode">Task</span> at the
front of its queue when the queue has work available, or sleeps when
no work is available.  Each task queue is associated with zero or
more worker threads.  If the result of a <span class="inlinecode">Task</span> is needed before execution
by a worker thread has begun, the <span class="inlinecode">Task</span> can be removed from the task queue
and executed immediately in the thread where the result is needed.

</p>
<b>Warning:</b><br>
Unless marked as <span class="inlinecode">@trusted</span> or <span class="inlinecode">@safe</span>, artifacts in
          this module allow implicit data sharing between threads and cannot
          guarantee that client code is free from low level data races.

<br><br>
<b>Synopsis:</b><br>
<pre class="d_code"><span class="d_keyword">import</span> std.algorithm, std.<u>parallelism</u>, std.range;

<span class="d_keyword">void</span> main() {
    <span class="d_comment">// Parallel reduce can be combined with std.algorithm.map to interesting
</span>
    <span class="d_comment">// effect.  The following example (thanks to Russel Winder) calculates
</span>
    <span class="d_comment">// pi by quadrature using std.algorithm.map and TaskPool.reduce.
</span>
    <span class="d_comment">// getTerm is evaluated in parallel as needed by TaskPool.reduce.
</span>
    <span class="d_comment">//
</span>
    <span class="d_comment">// Timings on an Athlon 64 X2 dual core machine:
</span>
    <span class="d_comment">//
</span>
    <span class="d_comment">// TaskPool.reduce:       12.170 s
</span>
    <span class="d_comment">// std.algorithm.reduce:  24.065 s
</span>

    <span class="d_keyword">immutable</span> n = 1_000_000_000;
    <span class="d_keyword">immutable</span> delta = 1.0 / n;

    <span class="d_keyword">real</span> getTerm(<span class="d_keyword">int</span> i)
    {
        <span class="d_keyword">immutable</span> x = ( i - 0.5 ) * delta;
        <span class="d_keyword">return</span> delta / ( 1.0 + x * x ) ;
    }

    <span class="d_keyword">immutable</span> pi = 4.0 * taskPool.reduce!<span class="d_string">"a + b"</span>(
        std.algorithm.map!getTerm(iota(n))
    );
}
</pre>

<br><br>
<b>Author:</b><br>
David Simcha
<br><br>
<div><b>License</b>: <a href="http://boost.org/LICENSE_1_0.txt">Boost License 1.0</a></div>

<hr><div class="row-fluid declaration"><h3>struct <a class="symbol symbol-anchor" name="Task" href="#Task">Task</a>(alias fun,Args...);
</h3></div>

<div class="declaration-content"><p><span class="inlinecode"><a class="symbol symbol-anchor" name="Task" href="#Task">Task</a></span> represents the fundamental unit of work.  A <span class="inlinecode"><a class="symbol symbol-anchor" name="Task" href="#Task">Task</a></span> may be
executed in parallel with any other <span class="inlinecode"><a class="symbol symbol-anchor" name="Task" href="#Task">Task</a></span>.  Using this struct directly
allows future/promise parallelism.  In this paradigm, a function (or delegate
or other callable) is executed in a thread other than the one it was called
from.  The calling thread does not block while the function is being executed.
A call to <span class="inlinecode">workForce</span>, <span class="inlinecode">yieldForce</span>, or <span class="inlinecode">spinForce</span> is used to
ensure that the <span class="inlinecode"><a class="symbol symbol-anchor" name="Task" href="#Task">Task</a></span> has finished executing and to obtain the return
value, if any.  These functions and <span class="inlinecode">done</span> also act as full memory barriers,
meaning that any memory writes made in the thread that executed the <span class="inlinecode"><a class="symbol symbol-anchor" name="Task" href="#Task">Task</a></span>
are guaranteed to be visible in the calling thread after one of these functions
returns.
</p>

<p>The <a href="std_parallelism.html#task"><span class="inlinecode">std.parallelism.task</span></a> and <a href="std_parallelism.html#scopedTask"><span class="inlinecode">std.parallelism.scopedTask</span></a> functions can
be used to create an instance of this struct.  See <span class="inlinecode">task</span> for usage examples.
<br><br>

Function results are returned from <span class="inlinecode">yieldForce</span>, <span class="inlinecode">spinForce</span> and
<span class="inlinecode">workForce</span> by ref.  If <span class="inlinecode">fun</span> returns by ref, the reference will point
to the returned reference of <span class="inlinecode">fun</span>.  Otherwise it will point to a
field in this struct.
<br><br>

Copying of this struct is disabled, since it would provide no useful semantics.
If you want to pass this struct around, you should do so by reference or
pointer.

</p>
<div><b>Known bugs</b>:<br/> &nbsp; &nbsp; &nbsp; Changes to <span class="inlinecode">ref</span> and <span class="inlinecode">out</span> arguments are not propagated to the
       call site, only to <span class="inlinecode">args</span> in this struct.</div>

<div class="offset1 member-list"><hr><div class="row-fluid declaration"><h3>alias <a class="symbol symbol-anchor" name="args" href="#args">args</a>;
</h3></div>

<div class="declaration-content"><p>The arguments the function was called with.  Changes to <span class="inlinecode">out</span> and
    <span class="inlinecode">ref</span> arguments will be visible here.</p>


</div>

<hr><div class="row-fluid declaration"><h3>alias <a class="symbol symbol-anchor" name="ReturnType" href="#ReturnType">ReturnType</a>;
</h3></div>

<div class="declaration-content"><p>The return type of the function called by this <span class="inlinecode">Task</span>.  This can be
    <span class="inlinecode">void</span>.</p>


</div>

<hr><div class="row-fluid declaration"><h3>@trusted ReturnType <a class="symbol symbol-anchor" name="spinForce" href="#spinForce">spinForce</a>();
</h3></div>

<div class="declaration-content"><p>If the <span class="inlinecode">Task</span> isn't started yet, execute it in the current thread.
    If it's done, return its return value, if any.  If it's in progress,
    busy spin until it's done, then return the return value.  If it threw
    an exception, rethrow that exception.
</p>

<p>This function should be used when you expect the result of the
    <span class="inlinecode">Task</span> to be available on a timescale shorter than that of an OS
    context switch.</p>

</div>

<hr><div class="row-fluid declaration"><h3>@trusted ReturnType <a class="symbol symbol-anchor" name="yieldForce" href="#yieldForce">yieldForce</a>();
</h3></div>

<div class="declaration-content"><p>If the <span class="inlinecode">Task</span> isn't started yet, execute it in the current thread.
    If it's done, return its return value, if any.  If it's in progress,
    wait on a condition variable.  If it threw an exception, rethrow that
    exception.
</p>

<p>This function should be used for expensive functions, as waiting on a
    condition variable introduces latency, but avoids wasted CPU cycles.</p>

</div>

<hr><div class="row-fluid declaration"><h3>@trusted ReturnType <a class="symbol symbol-anchor" name="workForce" href="#workForce">workForce</a>();
</h3></div>

<div class="declaration-content"><p>If this <span class="inlinecode">Task</span> was not started yet, execute it in the current
    thread.  If it is finished, return its result.  If it is in progress,
    execute any other <span class="inlinecode">Task</span> from the <span class="inlinecode">TaskPool</span> instance that
    this <span class="inlinecode">Task</span> was submitted to until this one
    is finished.  If it threw an exception, rethrow that exception.
    If no other tasks are available or this <span class="inlinecode">Task</span> was executed using
    <span class="inlinecode">executeInNewThread</span>, wait on a condition variable.</p>


</div>

<hr><div class="row-fluid declaration"><h3>@trusted bool <a class="symbol symbol-anchor" name="done" href="#done">done</a>();
</h3></div>

<div class="declaration-content"><p>Returns <span class="inlinecode"><span class="d_keyword">true</span></span> if the <span class="inlinecode">Task</span> is finished executing.
</p>

<div><b>Throws</b>:<br/> &nbsp; &nbsp; &nbsp; Rethrows any exception thrown during the execution of the
             <span class="inlinecode">Task</span>.</div>

</div>

<hr><div class="row-fluid declaration"><h3>@trusted void <a class="symbol symbol-anchor" name="executeInNewThread" href="#executeInNewThread">executeInNewThread</a>();
<br>@trusted void <a class="symbol symbol-anchor" name="executeInNewThread" href="#executeInNewThread">executeInNewThread</a>(int <i>priority</i>);
</h3></div>

<div class="declaration-content"><p>Create a new thread for executing this <span class="inlinecode">Task</span>, execute it in the
    newly created thread, then terminate the thread.  This can be used for
    future/promise parallelism.  An explicit priority may be given
    to the <span class="inlinecode">Task</span>.  If one is provided, its value is forwarded to
    <span class="inlinecode">core.thread.Thread.priority</span>. See <a href="std_parallelism.html#task"><span class="inlinecode">std.parallelism.task</span></a> for
    usage example.</p>


</div>

</div>
</div>

<hr><div class="row-fluid declaration"><h3>auto <a class="symbol symbol-anchor" name="task" href="#task">task</a>(alias fun, Args...)(Args <i>args</i>);
</h3></div>

<div class="declaration-content"><p>Creates a <span class="inlinecode">Task</span> on the GC heap that calls an alias.  This may be executed
via <span class="inlinecode">Task.executeInNewThread</span> or by submitting to a
<a href="std_parallelism.html#TaskPool"><span class="inlinecode">std.parallelism.TaskPool</span></a>.  A globally accessible instance of
<span class="inlinecode">TaskPool</span> is provided by <a href="std_parallelism.html#taskPool"><span class="inlinecode">std.parallelism.taskPool</span></a>.
</p>

<div><b>Returns</b>:<br/> &nbsp; &nbsp; &nbsp; A pointer to the <span class="inlinecode">Task</span>.

</div>
<div><b>Examples</b>:<br/> &nbsp; &nbsp; &nbsp; <pre class="d_code"><span class="d_comment">// Read two files into memory at the same time.
</span>
<span class="d_keyword">import</span> std.file;

<span class="d_keyword">void</span> main()
{
    <span class="d_comment">// Create and execute a Task for reading foo.txt.
</span>
    <span class="d_keyword">auto</span> file1Task = <u>task</u>!read(<span class="d_string">"foo.txt"</span>);
    file1Task.executeInNewThread();

    <span class="d_comment">// Read bar.txt in parallel.
</span>
    <span class="d_keyword">auto</span> file2Data = read(<span class="d_string">"bar.txt"</span>);

    <span class="d_comment">// Get the results of reading foo.txt.
</span>
    <span class="d_keyword">auto</span> file1Data = file1Task.yieldForce();
}
</pre>

<pre class="d_code"><span class="d_comment">// Sorts an array using a parallel quick sort algorithm.  The first partition
</span>
<span class="d_comment">// is done serially.  Both recursion branches are then executed in
</span>
<span class="d_comment">// parallel.
</span>
<span class="d_comment">//
</span>
<span class="d_comment">// Timings for sorting an array of 1,000,000 doubles on an Athlon 64 X2
</span>
<span class="d_comment">// dual core machine:
</span>
<span class="d_comment">//
</span>
<span class="d_comment">// This implementation:               176 milliseconds.
</span>
<span class="d_comment">// Equivalent serial implementation:  280 milliseconds
</span>
<span class="d_keyword">void</span> parallelSort(T)(T[] data)
{
    <span class="d_comment">// Sort small subarrays serially.
</span>
    <span class="d_keyword">if</span>(data.length &lt; 100)
    {
         std.algorithm.sort(data);
         <span class="d_keyword">return</span>;
    }

    <span class="d_comment">// Partition the array.
</span>
    swap(data[$ / 2], data[$ - 1]);
    <span class="d_keyword">auto</span> pivot = data[$ - 1];
    <span class="d_keyword">bool</span> lessThanPivot(T elem) { <span class="d_keyword">return</span> elem &lt; pivot; }

    <span class="d_keyword">auto</span> greaterEqual = partition!lessThanPivot(data[0..$ - 1]);
    swap(data[$ - greaterEqual.length - 1], data[$ - 1]);

    <span class="d_keyword">auto</span> less = data[0..$ - greaterEqual.length - 1];
    greaterEqual = data[$ - greaterEqual.length..$];

    <span class="d_comment">// Execute both recursion branches in parallel.
</span>
    <span class="d_keyword">auto</span> recurseTask = <u>task</u>!(parallelSort)(greaterEqual);
    taskPool.put(recurseTask);
    parallelSort(less);
    recurseTask.yieldForce();
}
</pre>
</div>

</div>

<hr><div class="row-fluid declaration"><h3>auto <a class="symbol symbol-anchor" name="task" href="#task">task</a>(F, Args...)(F <i>delegateOrFp</i>, Args <i>args</i>);
</h3></div>

<div class="declaration-content"><p>Creates a <span class="inlinecode">Task</span> on the GC heap that calls a function pointer, delegate, or
class/struct with overloaded opCall.
</p>

<div><b>Examples</b>:<br/> &nbsp; &nbsp; &nbsp; <pre class="d_code"><span class="d_comment">// Read two files in at the same time again, but this time use a function
</span>
<span class="d_comment">// pointer instead of an alias to represent std.file.read.
</span>
<span class="d_keyword">import</span> std.file;

<span class="d_keyword">void</span> main()
{
    <span class="d_comment">// Create and execute a Task for reading foo.txt.
</span>
    <span class="d_keyword">auto</span> file1Task = <u>task</u>(&amp;read, <span class="d_string">"foo.txt"</span>);
    file1Task.executeInNewThread();

    <span class="d_comment">// Read bar.txt in parallel.
</span>
    <span class="d_keyword">auto</span> file2Data = read(<span class="d_string">"bar.txt"</span>);

    <span class="d_comment">// Get the results of reading foo.txt.
</span>
    <span class="d_keyword">auto</span> file1Data = file1Task.yieldForce();
}
</pre>

</div>
<b>Notes:</b><br>
This function takes a non-scope delegate, meaning it can be
       used with closures.  If you can't allocate a closure due to objects
       on the stack that have scoped destruction, see <span class="inlinecode">scopedTask</span>, which
       takes a scope delegate.<br><br>

</div>

<hr><div class="row-fluid declaration"><h3>@trusted auto <a class="symbol symbol-anchor" name="task" href="#task">task</a>(F, Args...)(F <i>fun</i>, Args <i>args</i>);
</h3></div>

<div class="declaration-content"><p>Version of <span class="inlinecode"><a class="symbol symbol-anchor" name="task" href="#task">task</a></span> usable from <span class="inlinecode">@safe</span> code.  Usage mechanics are
identical to the non-@safe case, but safety introduces the some restrictions.
</p>

<p>1.  <span class="inlinecode">fun</span> must be @safe or @trusted.
<br><br>

2.  <span class="inlinecode">F</span> must not have any unshared aliasing as defined by
    <a href="std_traits.html#hasUnsharedAliasing"><span class="inlinecode">std.traits.hasUnsharedAliasing</span></a>.  This means it
    may not be an unshared delegate or a non-shared class or struct
    with overloaded <span class="inlinecode">opCall</span>.  This also precludes accepting template
    alias parameters.
<br><br>

3.  <span class="inlinecode">Args</span> must not have unshared aliasing.
<br><br>

4.  <span class="inlinecode">fun</span> must not return by reference.
<br><br>

5.  The return type must not have unshared aliasing unless <span class="inlinecode">fun</span> is
    <span class="inlinecode">pure</span> or the <span class="inlinecode">Task</span> is executed via <span class="inlinecode">executeInNewThread</span> instead
    of using a <span class="inlinecode">TaskPool</span>.</p>

</div>

<hr><div class="row-fluid declaration"><h3>auto <a class="symbol symbol-anchor" name="scopedTask" href="#scopedTask">scopedTask</a>(alias fun, Args...)(Args <i>args</i>);
<br>auto <a class="symbol symbol-anchor" name="scopedTask" href="#scopedTask">scopedTask</a>(F, Args...)(scope F <i>delegateOrFp</i>, Args <i>args</i>);
<br>@trusted auto <a class="symbol symbol-anchor" name="scopedTask" href="#scopedTask">scopedTask</a>(F, Args...)(F <i>fun</i>, Args <i>args</i>);
</h3></div>

<div class="declaration-content"><p>These functions allow the creation of <span class="inlinecode">Task</span> objects on the stack rather
than the GC heap.  The lifetime of a <span class="inlinecode">Task</span> created by <span class="inlinecode"><a class="symbol symbol-anchor" name="scopedTask" href="#scopedTask">scopedTask</a></span>
cannot exceed the lifetime of the scope it was created in.
</p>

<p><span class="inlinecode"><a class="symbol symbol-anchor" name="scopedTask" href="#scopedTask">scopedTask</a></span> might be preferred over <span class="inlinecode">task</span>:
<br><br>

1.  When a <span class="inlinecode">Task</span> that calls a delegate is being created and a closure
    cannot be allocated due to objects on the stack that have scoped
    destruction.  The delegate overload of <span class="inlinecode"><a class="symbol symbol-anchor" name="scopedTask" href="#scopedTask">scopedTask</a></span> takes a <span class="inlinecode">scope</span>
    delegate.
<br><br>

2.  As a micro-optimization, to avoid the heap allocation associated with
    <span class="inlinecode">task</span> or with the creation of a closure.
<br><br>

Usage is otherwise identical to <span class="inlinecode">task</span>.

</p>
<b>Notes:</b><br>
<span class="inlinecode">Task</span> objects created using <span class="inlinecode"><a class="symbol symbol-anchor" name="scopedTask" href="#scopedTask">scopedTask</a></span> will automatically
call <span class="inlinecode">Task.yieldForce</span> in their destructor if necessary to ensure
the <span class="inlinecode">Task</span> is complete before the stack frame they reside on is destroyed.<br><br>

</div>

<hr><div class="row-fluid declaration"><h3>immutable uint <a class="symbol symbol-anchor" name="totalCPUs" href="#totalCPUs">totalCPUs</a>;
</h3></div>

<div class="declaration-content"><p>The total number of CPU cores available on the current machine, as reported by
the operating system.</p>


</div>

<hr><div class="row-fluid declaration"><h3>class <a class="symbol symbol-anchor" name="TaskPool" href="#TaskPool">TaskPool</a>;
</h3></div>

<div class="declaration-content"><p>This class encapsulates a task queue and a set of worker threads.  Its purpose
is to efficiently map a large number of <span class="inlinecode">Task</span>s onto a smaller number of
threads.  A task queue is a FIFO queue of <span class="inlinecode">Task</span> objects that have been
submitted to the <span class="inlinecode"><a class="symbol symbol-anchor" name="TaskPool" href="#TaskPool">TaskPool</a></span> and are awaiting execution.  A worker thread is a
thread that executes the <span class="inlinecode">Task</span> at the front of the queue when one is
available and sleeps when the queue is empty.
</p>

<p>This class should usually be used via the global instantiation
available via the <a href="std_parallelism.html#taskPool"><span class="inlinecode">std.parallelism.taskPool</span></a> property.
Occasionally it is useful to explicitly instantiate a <span class="inlinecode"><a class="symbol symbol-anchor" name="TaskPool" href="#TaskPool">TaskPool</a></span>:
<br><br>

1.  When you want <span class="inlinecode"><a class="symbol symbol-anchor" name="TaskPool" href="#TaskPool">TaskPool</a></span> instances with multiple priorities, for example
    a low priority pool and a high priority pool.
<br><br>

2.  When the threads in the global task pool are waiting on a synchronization
    primitive (for example a mutex), and you want to parallelize the code that
    needs to run before these threads can be resumed.</p>

<div class="offset1 member-list"><hr><div class="row-fluid declaration"><h3>@trusted  this();
</h3></div>

<div class="declaration-content"><p>Default constructor that initializes a <span class="inlinecode">TaskPool</span> with
<span class="inlinecode">totalCPUs</span> - 1 worker threads.  The minus 1 is included because the
main thread will also be available to do work.
</p>

<b>Note:</b><br>
On single-core machines, the primitives provided by <span class="inlinecode">TaskPool</span>
       operate transparently in single-threaded mode.<br><br>

</div>

<hr><div class="row-fluid declaration"><h3>@trusted  this(uint <i>nWorkers</i>);
</h3></div>

<div class="declaration-content"><p>Allows for custom number of worker threads.</p>


</div>

<hr><div class="row-fluid declaration"><h3>ParallelForeach!(R) <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a>(R)(R <i>range</i>, size_t <i>workUnitSize</i>);
<br>ParallelForeach!(R) <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a>(R)(R <i>range</i>);
</h3></div>

<div class="declaration-content"><p>Implements a <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a> foreach loop over a range.  This works by implicitly
    creating and submitting one <span class="inlinecode">Task</span> to the <span class="inlinecode">TaskPool</span> for each worker
    thread.  A work unit is a set of consecutive elements of <span class="inlinecode">range</span> to
    be processed by a worker thread between communication with any other
    thread.  The number of elements processed per work unit is controlled by the
    <span class="inlinecode">workUnitSize</span> parameter.  Smaller work units provide better load
    balancing, but larger work units avoid the overhead of communicating
    with other threads frequently to fetch the next work unit.  Large work
    units also avoid <span class="d_keyword">false</span> sharing in cases where the range is being modified.
    The less time a single iteration of the loop takes, the larger
    <span class="inlinecode">workUnitSize</span> should be.  For very expensive loop bodies,
    <span class="inlinecode">workUnitSize</span> should  be 1.  An overload that chooses a default work
    unit size is also available.
</p>

<div><b>Examples</b>:<br/> &nbsp; &nbsp; &nbsp; <pre class="d_code">    <span class="d_comment">// Find the logarithm of every number from 1 to
</span>
    <span class="d_comment">// 10_000_000 in parallel.
</span>
    <span class="d_keyword">auto</span> logs = <span class="d_keyword">new</span> <span class="d_keyword">double</span>[10_000_000];

    <span class="d_comment">// Parallel foreach works with or without an index
</span>
    <span class="d_comment">// variable.  It can be iterate by ref if range.front
</span>
    <span class="d_comment">// returns by ref.
</span>

    <span class="d_comment">// Iterate over logs using work units of size 100.
</span>
    <span class="d_keyword">foreach</span>(i, <span class="d_keyword">ref</span> elem; taskPool.<u>parallel</u>(logs, 100))
    {
        elem = log(i + 1.0);
    }

    <span class="d_comment">// Same thing, but use the default work unit size.
</span>
    <span class="d_comment">//
</span>
    <span class="d_comment">// Timings on an Athlon 64 X2 dual core machine:
</span>
    <span class="d_comment">//
</span>
    <span class="d_comment">// Parallel foreach:  388 milliseconds
</span>
    <span class="d_comment">// Regular foreach:   619 milliseconds
</span>
    <span class="d_keyword">foreach</span>(i, <span class="d_keyword">ref</span> elem; taskPool.<u>parallel</u>(logs))
    {
        elem = log(i + 1.0);
    }
</pre>

</div>
<b>Notes:</b><br>
The memory usage of this implementation is guaranteed to be constant
    in <span class="inlinecode">range.length</span>.
<br><br>

    Breaking from a <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a> foreach loop via a break, labeled break,
    labeled continue, return or goto statement throws a
    <span class="inlinecode">ParallelForeachError</span>.
<br><br>

    In the case of non-random access ranges, <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a> foreach buffers lazily
    to an array of size <span class="inlinecode">workUnitSize</span> before executing the <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a> portion
    of the loop.  The exception is that, if a <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a> foreach is executed
    over a range returned by <span class="inlinecode">asyncBuf</span> or <span class="inlinecode">map</span>, the copying is elided
    and the buffers are simply swapped.  In this case <span class="inlinecode">workUnitSize</span> is
    ignored and the work unit size is set to the  buffer size of <span class="inlinecode">range</span>.
<br><br>

    A memory barrier is guaranteed to be executed on exit from the loop,
    so that results produced by all threads are visible in the calling thread.
<br><br>

    <b>Exception Handling</b>:
<br><br>

    When at least one exception is thrown from inside a <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a> foreach loop,
    the submission of additional <span class="inlinecode">Task</span> objects is terminated as soon as
    possible, in a non-deterministic manner.  All executing or
    enqueued work units are allowed to complete.  Then, all exceptions that
    were thrown by any work unit are chained using <span class="inlinecode">Throwable.next</span> and
    rethrown.  The order of the exception chaining is non-deterministic.<br><br>

</div>

<hr><div class="row-fluid declaration"><h3>template <a class="symbol symbol-anchor" name="amap" href="#amap">amap</a>(functions...)</h3></div>

<div class="declaration-content"><p>Eager parallel map.  The eagerness of this function means it has less
    overhead than the lazily evaluated <span class="inlinecode">TaskPool.map</span> and should be
    preferred where the memory requirements of eagerness are acceptable.
    <span class="inlinecode">functions</span> are the functions to be evaluated, passed as template alias
    parameters in a style similar to <a href="std_algorithm.html#map"><span class="inlinecode">std.algorithm.map</span></a>.  The first
    argument must be a random access range.
</p>

<p><pre class="d_code">    <span class="d_keyword">auto</span> numbers = iota(100_000_000.0);

    <span class="d_comment">// Find the square roots of numbers.
</span>
    <span class="d_comment">//
</span>
    <span class="d_comment">// Timings on an Athlon 64 X2 dual core machine:
</span>
    <span class="d_comment">//
</span>
    <span class="d_comment">// Parallel eager map:                   0.802 s
</span>
    <span class="d_comment">// Equivalent serial implementation:     1.768 s
</span>
    <span class="d_keyword">auto</span> squareRoots = taskPool.<u>amap</u>!sqrt(numbers);
</pre>

    Immediately after the range argument, an optional work unit size argument
    may be provided.  Work units as used by <span class="inlinecode"><a class="symbol symbol-anchor" name="amap" href="#amap">amap</a></span> are identical to those
    defined for parallel foreach.  If no work unit size is provided, the
    default work unit size is used.
<br><br>

<pre class="d_code">    <span class="d_comment">// Same thing, but make work unit size 100.
</span>
    <span class="d_keyword">auto</span> squareRoots = taskPool.<u>amap</u>!sqrt(numbers, 100);
</pre>

    An output range for returning the results may be provided as the last
    argument.  If one is not provided, an array of the proper type will be
    allocated on the garbage collected heap.  If one is provided, it must be a
    random access range with assignable elements, must have reference
    semantics with respect to assignment to its elements, and must have the
    same length as the input range.  Writing to adjacent elements from
    different threads must be safe.
<br><br>

<pre class="d_code">    <span class="d_comment">// Same thing, but explicitly allocate an array
</span>
    <span class="d_comment">// to return the results in.  The element type
</span>
    <span class="d_comment">// of the array may be either the exact type
</span>
    <span class="d_comment">// returned by functions or an implicit conversion
</span>
    <span class="d_comment">// target.
</span>
    <span class="d_keyword">auto</span> squareRoots = <span class="d_keyword">new</span> <span class="d_keyword">float</span>[numbers.length];
    taskPool.<u>amap</u>!sqrt(numbers, squareRoots);

    <span class="d_comment">// Multiple functions, explicit output range, and
</span>
    <span class="d_comment">// explicit work unit size.
</span>
    <span class="d_keyword">auto</span> results = <span class="d_keyword">new</span> Tuple!(<span class="d_keyword">float</span>, <span class="d_keyword">real</span>)[numbers.length];
    taskPool.<u>amap</u>!(sqrt, log)(numbers, 100, results);
</pre>

</p>
<b>Note:</b><br>
A memory barrier is guaranteed to be executed after all results are written
    but before returning so that results produced by all threads are visible
    in the calling thread.

<br><br>
<b>Tips:</b><br>
To perform the mapping operation in place, provide the same range for the
    input and output range.
<br><br>

    To parallelize the copying of a range with expensive to evaluate elements
    to an array, pass an identity function (a function that just returns
    whatever argument is provided to it) to <span class="inlinecode"><a class="symbol symbol-anchor" name="amap" href="#amap">amap</a></span>.
<br><br>

    <b>Exception Handling</b>:
<br><br>

    When at least one exception is thrown from inside the map functions,
    the submission of additional <span class="inlinecode">Task</span> objects is terminated as soon as
    possible, in a non-deterministic manner.  All currently executing or
    enqueued work units are allowed to complete.  Then, all exceptions that
    were thrown from any work unit are chained using <span class="inlinecode">Throwable.next</span> and
    rethrown.  The order of the exception chaining is non-deterministic.<br><br>

<div class="offset1 member-list"><hr><div class="row-fluid declaration"><h3>auto <a class="symbol symbol-anchor" name="amap" href="#amap">amap</a>(Args...)(Args <i>args</i>);
</h3></div>

<div class="declaration-content"><br><br>
</div>

</div>
</div>

<hr><div class="row-fluid declaration"><h3>template <a class="symbol symbol-anchor" name="map" href="#map">map</a>(functions...)</h3></div>

<div class="declaration-content"><p>A semi-lazy parallel <a class="symbol symbol-anchor" name="map" href="#map">map</a> that can be used for pipelining.  The <a class="symbol symbol-anchor" name="map" href="#map">map</a>
    functions are evaluated for the first <span class="inlinecode">bufSize</span> elements and stored in a
    buffer and made available to <span class="inlinecode">popFront</span>.  Meanwhile, in the
    background a second buffer of the same size is filled.  When the first
    buffer is exhausted, it is swapped with the second buffer and filled while
    the values from what was originally the second buffer are read.  This
    implementation allows for elements to be written to the buffer without
    the need for atomic operations or synchronization for each write, and
    enables the mapping function to be evaluated efficiently in parallel.
</p>

<p><span class="inlinecode"><a class="symbol symbol-anchor" name="map" href="#map">map</a></span> has more overhead than the simpler procedure used by <span class="inlinecode">amap</span>
    but avoids the need to keep all results in memory simultaneously and works
    with non-random access ranges.

</p>
<b>Parameters</b> <div><table class="table table-condensed table-bordered"><tr><td class="span2">source</td>
<td>The input range to be mapped.  If <span class="inlinecode">source</span> is not random
    access it will be lazily buffered to an array of size <span class="inlinecode">bufSize</span> before
    the <a class="symbol symbol-anchor" name="map" href="#map">map</a> function is evaluated.  (For an exception to this rule, see Notes.)</td>
</tr>
<tr><td class="span2">bufSize</td>
<td>The size of the buffer to store the evaluated elements.</td>
</tr>
<tr><td class="span2">workUnitSize</td>
<td>The number of elements to evaluate in a single
    <span class="inlinecode">Task</span>.  Must be less than or equal to <span class="inlinecode">bufSize</span>, and
    should be a fraction of <span class="inlinecode">bufSize</span> such that all worker threads can be
    used.  If the default of size_t.max is used, workUnitSize will be set to
    the pool-wide default.</td>
</tr>
</table></div>
<div><b>Returns</b>:<br/> &nbsp; &nbsp; &nbsp; An input range representing the results of the <a class="symbol symbol-anchor" name="map" href="#map">map</a>.  This range
              has a length iff <span class="inlinecode">source</span> has a length.

</div>
<b>Notes:</b><br>
If a range returned by <span class="inlinecode"><a class="symbol symbol-anchor" name="map" href="#map">map</a></span> or <span class="inlinecode">asyncBuf</span> is used as an input to
    <span class="inlinecode"><a class="symbol symbol-anchor" name="map" href="#map">map</a></span>, then as an optimization the copying from the output buffer
    of the first range to the input buffer of the second range is elided, even
    though the ranges returned by <span class="inlinecode"><a class="symbol symbol-anchor" name="map" href="#map">map</a></span> and <span class="inlinecode">asyncBuf</span> are non-random
    access ranges.  This means that the <span class="inlinecode">bufSize</span> parameter passed to the
    current call to <span class="inlinecode"><a class="symbol symbol-anchor" name="map" href="#map">map</a></span> will be ignored and the size of the buffer
    will be the buffer size of <span class="inlinecode">source</span>.

<br><br>
<div><b>Examples</b>:<br/> &nbsp; &nbsp; &nbsp; <pre class="d_code">    <span class="d_comment">// Pipeline reading a file, converting each line to a number, taking the
</span>
    <span class="d_comment">// logarithms of the numbers, and performing the additions necessary to
</span>
    <span class="d_comment">// find the sum of the logarithms.
</span>

    <span class="d_keyword">auto</span> lineRange = File(<span class="d_string">"numberList.txt"</span>).byLine();
    <span class="d_keyword">auto</span> dupedLines = std.algorithm.<u>map</u>!<span class="d_string">"a.idup"</span>(lineRange);
    <span class="d_keyword">auto</span> nums = taskPool.<u>map</u>!(to!<span class="d_keyword">double</span>)(dupedLines);
    <span class="d_keyword">auto</span> logs = taskPool.<u>map</u>!log10(nums);

    <span class="d_keyword">double</span> sum = 0;
    <span class="d_keyword">foreach</span>(elem; logs)
    {
        sum += elem;
    }
</pre>

    <b>Exception Handling</b>:
<br><br>

    Any exceptions thrown while iterating over <span class="inlinecode">source</span>
    or computing the <a class="symbol symbol-anchor" name="map" href="#map">map</a> function are re-thrown on a call to <span class="inlinecode">popFront</span> or,
    if thrown during construction, are simply allowed to propagate to the
    caller.  In the case of exceptions thrown while computing the <a class="symbol symbol-anchor" name="map" href="#map">map</a> function,
    the exceptions are chained as in <span class="inlinecode">TaskPool.amap</span>.</div>

<div class="offset1 member-list"><hr><div class="row-fluid declaration"><h3>auto <a class="symbol symbol-anchor" name="map" href="#map">map</a>(S)(S <i>source</i>, size_t <i>bufSize</i> = 100, size_t <i>workUnitSize</i> = size_t.max);
</h3></div>

<div class="declaration-content"><br><br>
</div>

</div>
</div>

<hr><div class="row-fluid declaration"><h3>auto <a class="symbol symbol-anchor" name="asyncBuf" href="#asyncBuf">asyncBuf</a>(S)(S <i>source</i>, size_t <i>bufSize</i> = 100);
</h3></div>

<div class="declaration-content"><p>Given a <span class="inlinecode">source</span> range that is expensive to iterate over, returns an
    input range that asynchronously buffers the contents of
    <span class="inlinecode">source</span> into a buffer of <span class="inlinecode">bufSize</span> elements in a worker thread,
    while making prevously buffered elements from a second buffer, also of size
    <span class="inlinecode">bufSize</span>, available via the range interface of the returned
    object.  The returned range has a length iff <span class="inlinecode">hasLength!(S)</span>.
    <span class="inlinecode"><a class="symbol symbol-anchor" name="asyncBuf" href="#asyncBuf">asyncBuf</a></span> is useful, for example, when performing expensive operations
    on the elements of ranges that represent data on a disk or network.
</p>

<div><b>Examples</b>:<br/> &nbsp; &nbsp; &nbsp; <pre class="d_code">    <span class="d_keyword">import</span> std.conv, std.stdio;

    <span class="d_keyword">void</span> main()
    {
        <span class="d_comment">// Fetch lines of a file in a background thread
</span>
        <span class="d_comment">// while processing prevously fetched lines,
</span>
        <span class="d_comment">// dealing with byLine's buffer recycling by
</span>
        <span class="d_comment">// eagerly duplicating every line.
</span>
        <span class="d_keyword">auto</span> lines = File(<span class="d_string">"foo.txt"</span>).byLine();
        <span class="d_keyword">auto</span> duped = std.algorithm.map!<span class="d_string">"a.idup"</span>(lines);

        <span class="d_comment">// Fetch more lines in the background while we
</span>
        <span class="d_comment">// process the lines already read into memory
</span>
        <span class="d_comment">// into a matrix of doubles.
</span>
        <span class="d_keyword">double</span>[][] matrix;
        <span class="d_keyword">auto</span> asyncReader = taskPool.<u>asyncBuf</u>(duped);

        <span class="d_keyword">foreach</span>(line; asyncReader)
        {
            <span class="d_keyword">auto</span> ls = line.split(<span class="d_string">"\t"</span>);
            matrix ~= to!(<span class="d_keyword">double</span>[])(ls);
        }
    }
</pre>

    <b>Exception Handling</b>:
<br><br>

    Any exceptions thrown while iterating over <span class="inlinecode">source</span> are re-thrown on a
    call to <span class="inlinecode">popFront</span> or, if thrown during construction, simply
    allowed to propagate to the caller.</div>

</div>

<hr><div class="row-fluid declaration"><h3>auto <a class="symbol symbol-anchor" name="asyncBuf" href="#asyncBuf">asyncBuf</a>(C1, C2)(C1 <i>next</i>, C2 <i>empty</i>, size_t <i>initialBufSize</i> = 0, size_t <i>nBuffers</i> = 100);
</h3></div>

<div class="declaration-content"><p>Given a callable object <span class="inlinecode">next</span> that writes to a user-provided buffer and
    a second callable object <span class="inlinecode">empty</span> that determines whether more data is
    available to write via <span class="inlinecode">next</span>, returns an input range that
    asynchronously calls <span class="inlinecode">next</span> with a set of size <span class="inlinecode">nBuffers</span> of buffers
    and makes the results available in the order they were obtained via the
    input range interface of the returned object.  Similarly to the
    input range overload of <span class="inlinecode"><a class="symbol symbol-anchor" name="asyncBuf" href="#asyncBuf">asyncBuf</a></span>, the first half of the buffers
    are made available via the range interface while the second half are
    filled and vice-versa.
</p>

<b>Parameters</b> <div><table class="table table-condensed table-bordered"><tr><td class="span2">next</td>
<td>A callable object that takes a single argument that must be an array
           with mutable elements.  When called, <span class="inlinecode">next</span> writes data to
           the array provided by the caller.</td>
</tr>
<tr><td class="span2">empty</td>
<td>A callable object that takes no arguments and returns a type
            implicitly convertible to <span class="inlinecode">bool</span>.  This is used to signify
            that no more data is available to be obtained by calling <span class="inlinecode">next</span>.</td>
</tr>
<tr><td class="span2">initialBufSize</td>
<td>The initial size of each buffer.  If <span class="inlinecode">next</span> takes its
                     array by reference, it may resize the buffers.</td>
</tr>
<tr><td class="span2">nBuffers</td>
<td>The number of buffers to cycle through when calling <span class="inlinecode">next</span>.</td>
</tr>
</table></div>
<div><b>Examples</b>:<br/> &nbsp; &nbsp; &nbsp; <pre class="d_code">    <span class="d_comment">// Fetch lines of a file in a background thread while processing prevously
</span>
    <span class="d_comment">// fetched lines, without duplicating any lines.
</span>
    <span class="d_keyword">auto</span> file = File(<span class="d_string">"foo.txt"</span>);

    <span class="d_keyword">void</span> next(<span class="d_keyword">ref</span> <span class="d_keyword">char</span>[] buf)
    {
        file.readln(buf);
    }

    <span class="d_comment">// Fetch more lines in the background while we process the lines already
</span>
    <span class="d_comment">// read into memory into a matrix of doubles.
</span>
    <span class="d_keyword">double</span>[][] matrix;
    <span class="d_keyword">auto</span> asyncReader = taskPool.<u>asyncBuf</u>(&amp;next, &amp;file.eof);

    <span class="d_keyword">foreach</span>(line; asyncReader)
    {
        <span class="d_keyword">auto</span> ls = line.split(<span class="d_string">"\t"</span>);
        matrix ~= to!(<span class="d_keyword">double</span>[])(ls);
    }
</pre>

    <b>Exception Handling</b>:
<br><br>

    Any exceptions thrown while iterating over <span class="inlinecode">range</span> are re-thrown on a
    call to <span class="inlinecode">popFront</span>.

</div>
<b>Warning:</b><br>
Using the range returned by this function in a parallel foreach loop
    will not work because buffers may be overwritten while the task that
    processes them is in queue.  This is checked for at compile time
    and will result in a static assertion failure.<br><br>

</div>

<hr><div class="row-fluid declaration"><h3>template <a class="symbol symbol-anchor" name="reduce" href="#reduce">reduce</a>(functions...)</h3></div>

<div class="declaration-content"><p>Parallel <a class="symbol symbol-anchor" name="reduce" href="#reduce">reduce</a> on a random access range.  Except as otherwise noted, usage
    is similar to <a href="std_algorithm.html#reduce"><span class="inlinecode">std.algorithm.reduce</span></a>.  This function works by splitting
    the range to be reduced into work units, which are slices to be reduced in
    parallel.  Once the results from all work units are computed, a final serial
    reduction is performed on these results to compute the final answer.
    Therefore, care must be taken to choose the seed value appropriately.
</p>

<p>Because the reduction is being performed in parallel,
    <span class="inlinecode">functions</span> must be associative.  For notational simplicity, let # be an
    infix operator representing <span class="inlinecode">functions</span>.  Then, (a # b) # c must equal
    a # (b # c).  Floating point addition is not associative
    even though addition in exact arithmetic is.  Summing floating
    point numbers using this function may give different results than summing
    serially.  However, for many practical purposes floating point addition
    can be treated as associative.
<br><br>

    Note that, since <span class="inlinecode">functions</span> are assumed to be associative, additional
    optimizations are made to the serial portion of the reduction algorithm.
    These take advantage of the instruction level parallelism of modern CPUs,
    in addition to the thread-level parallelism that the rest of this
    module exploits.  This can lead to better than linear speedups relative
    to <a href="std_algorithm.html#reduce"><span class="inlinecode">std.algorithm.reduce</span></a>, especially for fine-grained benchmarks
    like dot products.
<br><br>

    An explicit seed may be provided as the first argument.  If
    provided, it is used as the seed for all work units and for the final
    reduction of results from all work units.  Therefore, if it is not the
    identity value for the operation being performed, results may differ from
    those generated by <a href="std_algorithm.html#reduce"><span class="inlinecode">std.algorithm.reduce</span></a> or depending on how many work
    units are used.  The next argument must be the range to be reduced.
<pre class="d_code">    <span class="d_comment">// Find the sum of squares of a range in parallel, using an explicit seed.
</span>
    <span class="d_comment">//
</span>
    <span class="d_comment">// Timings on an Athlon 64 X2 dual core machine:
</span>
    <span class="d_comment">//
</span>
    <span class="d_comment">// Parallel reduce:                     72 milliseconds
</span>
    <span class="d_comment">// Using std.algorithm.reduce instead:  181 milliseconds
</span>
    <span class="d_keyword">auto</span> nums = iota(10_000_000.0f);
    <span class="d_keyword">auto</span> sumSquares = taskPool.<u>reduce</u>!<span class="d_string">"a + b"</span>(
        0.0, std.algorithm.map!<span class="d_string">"a * a"</span>(nums)
    );
</pre>

    If no explicit seed is provided, the first element of each work unit
    is used as a seed.  For the final reduction, the result from the first
    work unit is used as the seed.
<pre class="d_code">    <span class="d_comment">// Find the sum of a range in parallel, using the first element of each
</span>
    <span class="d_comment">// work unit as the seed.
</span>
    <span class="d_keyword">auto</span> sum = taskPool.<u>reduce</u>!<span class="d_string">"a + b"</span>(nums);
</pre>

    An explicit work unit size may be specified as the last argument.
    Specifying too small a work unit size will effectively serialize the
    reduction, as the final reduction of the result of each work unit will
    dominate computation time.  If <span class="inlinecode">TaskPool.size</span> for this instance
    is zero, this parameter is ignored and one work unit is used.
<pre class="d_code">    <span class="d_comment">// Use a work unit size of 100.
</span>
    <span class="d_keyword">auto</span> sum2 = taskPool.<u>reduce</u>!<span class="d_string">"a + b"</span>(nums, 100);

    <span class="d_comment">// Work unit size of 100 and explicit seed.
</span>
    <span class="d_keyword">auto</span> sum3 = taskPool.<u>reduce</u>!<span class="d_string">"a + b"</span>(0.0, nums, 100);
</pre>

    Parallel <a class="symbol symbol-anchor" name="reduce" href="#reduce">reduce</a> supports multiple functions, like
    <span class="inlinecode">std.algorithm.<a class="symbol symbol-anchor" name="reduce" href="#reduce">reduce</a></span>.
<pre class="d_code">    <span class="d_comment">// Find both the min and max of nums.
</span>
    <span class="d_keyword">auto</span> minMax = taskPool.<u>reduce</u>!(min, max)(nums);
    <span class="d_keyword">assert</span>(minMax[0] == <u>reduce</u>!min(nums));
    <span class="d_keyword">assert</span>(minMax[1] == <u>reduce</u>!max(nums));
</pre>

    <b>Exception Handling</b>:
<br><br>

    After this function is finished executing, any exceptions thrown
    are chained together via <span class="inlinecode">Throwable.next</span> and rethrown.  The chaining
    order is non-deterministic.</p>

<div class="offset1 member-list"><hr><div class="row-fluid declaration"><h3>auto <a class="symbol symbol-anchor" name="reduce" href="#reduce">reduce</a>(Args...)(Args <i>args</i>);
</h3></div>

<div class="declaration-content"><br><br>
</div>

</div>
</div>

<hr><div class="row-fluid declaration"><h3>const nothrow @property @safe size_t <a class="symbol symbol-anchor" name="workerIndex" href="#workerIndex">workerIndex</a>();
</h3></div>

<div class="declaration-content"><p>Gets the index of the current thread relative to this <span class="inlinecode">TaskPool</span>.  Any
    thread not in this pool will receive an index of 0.  The worker threads in
    this pool receive unique indices of 1 through <span class="inlinecode">this.size</span>.
</p>

<p>This function is useful for maintaining worker-local resources.

</p>
<div><b>Examples</b>:<br/> &nbsp; &nbsp; &nbsp; <pre class="d_code">    <span class="d_comment">// Execute a loop that computes the greatest common divisor of every
</span>
    <span class="d_comment">// number from 0 through 999 with 42 in parallel.  Write the results out to
</span>
    <span class="d_comment">// a set of files, one for each thread.  This allows results to be written
</span>
    <span class="d_comment">// out without any synchronization.
</span>

    <span class="d_keyword">import</span> std.stdio, std.conv, std.range, std.numeric;

    <span class="d_keyword">void</span> main()
    {
        <span class="d_keyword">auto</span> filesHandles = <span class="d_keyword">new</span> File[taskPool.size + 1];
        <span class="d_keyword">scope</span>(exit) {
            <span class="d_keyword">foreach</span>(<span class="d_keyword">ref</span> handle; fileHandles) {
                handle.close();
            }
        }

        <span class="d_keyword">foreach</span>(i, <span class="d_keyword">ref</span> handle; fileHandles)
        {
            handle = File(<span class="d_string">"workerResults"</span> ~ to!string(i) ~ <span class="d_string">".txt"</span>);
        }

        <span class="d_keyword">foreach</span>(num; parallel(iota(1_000)))
        {
            <span class="d_keyword">auto</span> outHandle = fileHandles[taskPool.<u>workerIndex</u>];
            outHandle.writeln(num, '\t', gcd(num, 42));
        }
    }
</pre>
</div>

</div>

<hr><div class="row-fluid declaration"><h3>struct <a class="symbol symbol-anchor" name="WorkerLocalStorage" href="#WorkerLocalStorage">WorkerLocalStorage</a>(T);
</h3></div>

<div class="declaration-content"><p>Struct for creating worker-local storage.  Worker-local storage is
    thread-local storage that exists only for worker threads in a given
    <span class="inlinecode">TaskPool</span> plus a single thread outside the pool.  It is allocated on the
    garbage collected heap in a way that avoids false sharing, and doesn't
    necessarily have global scope within any thread.  It can be accessed from
    any worker thread in the <span class="inlinecode">TaskPool</span> that created it, and one thread
    outside this <span class="inlinecode">TaskPool</span>.  All threads outside the pool that created a
    given instance of worker-local storage share a single slot.
</p>

<p>Since the underlying data for this struct is heap-allocated, this struct
    has reference semantics when passed between functions.
<br><br>

    The main uses cases for <span class="inlinecode">WorkerLocalStorageStorage</span> are:
<br><br>

    1.  Performing parallel reductions with an imperative, as opposed to
    functional, programming style.  In this case, it's useful to treat
    <span class="inlinecode">WorkerLocalStorageStorage</span> as local to each thread for only the parallel
    portion of an algorithm.
<br><br>

    2.  Recycling temporary buffers across iterations of a parallel foreach loop.

</p>
<div><b>Examples</b>:<br/> &nbsp; &nbsp; &nbsp; <pre class="d_code">    <span class="d_comment">// Calculate pi as in our synopsis example, but
</span>
    <span class="d_comment">// use an imperative instead of a functional style.
</span>
    <span class="d_keyword">immutable</span> n = 1_000_000_000;
    <span class="d_keyword">immutable</span> delta = 1.0L / n;

    <span class="d_keyword">auto</span> sums = taskPool.workerLocalStorage(0.0L);
    <span class="d_keyword">foreach</span>(i; parallel(iota(n)))
    {
        <span class="d_keyword">immutable</span> x = ( i - 0.5L ) * delta;
        <span class="d_keyword">immutable</span> toAdd = delta / ( 1.0 + x * x );
        sums.get += toAdd;
    }

    <span class="d_comment">// Add up the results from each worker thread.
</span>
    <span class="d_keyword">real</span> pi = 0;
    <span class="d_keyword">foreach</span>(threadResult; sums.toRange)
    {
        pi += 4.0L * threadResult;
    }
</pre>
</div>

<div class="offset1 member-list"><hr><div class="row-fluid declaration"><h3>@property T <a class="symbol symbol-anchor" name="get" href="#get">get</a>();
</h3></div>

<div class="declaration-content"><p>Get the current thread's instance.  Returns by ref.
        Note that calling <span class="inlinecode"><a class="symbol symbol-anchor" name="get" href="#get">get</a></span> from any thread
        outside the <span class="inlinecode">TaskPool</span> that created this instance will return the
        same reference, so an instance of worker-local storage should only be
        accessed from one thread outside the pool that created it.  If this
        rule is violated, undefined behavior will result.
</p>

<p>If assertions are enabled and <span class="inlinecode">toRange</span> has been called, then this
        WorkerLocalStorage instance is no longer worker-local and an assertion
        failure will result when calling this method.  This is not checked
        when assertions are disabled for performance reasons.</p>

</div>

<hr><div class="row-fluid declaration"><h3>@property void <a class="symbol symbol-anchor" name="get" href="#get">get</a>(T <i>val</i>);
</h3></div>

<div class="declaration-content"><p>Assign a value to the current thread's instance.  This function has
        the same caveats as its overload.</p>


</div>

<hr><div class="row-fluid declaration"><h3>@property WorkerLocalStorageRange!(T) <a class="symbol symbol-anchor" name="toRange" href="#toRange">toRange</a>();
</h3></div>

<div class="declaration-content"><p>Returns a range view of the values for all threads, which can be used
        to further process the results of each thread after running the parallel
        part of your algorithm.  Do not use this method in the parallel portion
        of your algorithm.
</p>

<p>Calling this function sets a flag indicating that this struct is no
        longer worker-local, and attempting to use the <span class="inlinecode">get</span> method again
        will result in an assertion failure if assertions are enabled.</p>

</div>

</div>
</div>

<hr><div class="row-fluid declaration"><h3>struct <a class="symbol symbol-anchor" name="WorkerLocalStorageRange" href="#WorkerLocalStorageRange">WorkerLocalStorageRange</a>(T);
</h3></div>

<div class="declaration-content"><p>Range primitives for worker-local storage.  The purpose of this is to
    access results produced by each worker thread from a single thread once you
    are no longer using the worker-local storage from multiple threads.
    Do not use this struct in the parallel portion of your algorithm.
</p>

<p>The proper way to instantiate this object is to call
    <span class="inlinecode">WorkerLocalStorage.toRange</span>.  Once instantiated, this object behaves
    as a finite random-access range with assignable, lvalue elemends and
    a length equal to the number of worker threads in the <span class="inlinecode">TaskPool</span> that
    created it plus 1.</p>

</div>

<hr><div class="row-fluid declaration"><h3>WorkerLocalStorage!(T) <a class="symbol symbol-anchor" name="workerLocalStorage" href="#workerLocalStorage">workerLocalStorage</a>(T)(lazy T <i>initialVal</i> = T.init);
</h3></div>

<div class="declaration-content"><p>Creates an instance of worker-local storage, initialized with a given
    value.  The value is <span class="inlinecode">lazy</span> so that you can, for example, easily
    create one instance of a class for each worker.  For usage example,
    see the <span class="inlinecode">WorkerLocalStorage</span> struct.</p>


</div>

<hr><div class="row-fluid declaration"><h3>@trusted void <a class="symbol symbol-anchor" name="stop" href="#stop">stop</a>();
</h3></div>

<div class="declaration-content"><p>Signals to all worker threads to terminate as soon as they are finished
    with their current <span class="inlinecode">Task</span>, or immediately if they are not executing a
    <span class="inlinecode">Task</span>.  <span class="inlinecode">Task</span>s that were in queue will not be executed unless
    a call to <span class="inlinecode">Task.workForce</span>, <span class="inlinecode">Task.yieldForce</span> or <span class="inlinecode">Task.spinForce</span>
    causes them to be executed.
</p>

<p>Use only if you have waitied on every <span class="inlinecode">Task</span> and therefore know the
    queue is empty, or if you speculatively executed some tasks and no longer
    need the results.</p>

</div>

<hr><div class="row-fluid declaration"><h3>@trusted void <a class="symbol symbol-anchor" name="finish" href="#finish">finish</a>();
</h3></div>

<div class="declaration-content"><p>Signals worker threads to terminate when the queue becomes empty.  Does
    not block.</p>


</div>

<hr><div class="row-fluid declaration"><h3>const pure nothrow @property @safe size_t <a class="symbol symbol-anchor" name="size" href="#size">size</a>();
</h3></div>

<div class="declaration-content"><p>Returns the number of worker threads in the pool.</p>


</div>

<hr><div class="row-fluid declaration"><h3>void <a class="symbol symbol-anchor" name="put" href="#put">put</a>(alias fun, Args...)(ref Task!(fun,Args) <i>task</i>);
<br>void <a class="symbol symbol-anchor" name="put" href="#put">put</a>(alias fun, Args...)(Task!(fun,Args)* <i>task</i>);
</h3></div>

<div class="declaration-content"><p>Put a <span class="inlinecode">Task</span> object on the back of the task queue.  The <span class="inlinecode">Task</span>
    object may be passed by pointer or reference.
</p>

<b>Example:</b><br>
<pre class="d_code">    <span class="d_keyword">import</span> std.file;

    <span class="d_comment">// Create a task.
</span>
    <span class="d_keyword">auto</span> t = task!read(<span class="d_string">"foo.txt"</span>);

    <span class="d_comment">// Add it to the queue to be executed.
</span>
    taskPool.<u>put</u>(t);
</pre>

<br><br>
<b>Notes:</b><br>
@trusted overloads of this function are called for <span class="inlinecode">Task</span>s if
    <a href="std_traits.html#hasUnsharedAliasing"><span class="inlinecode">std.traits.hasUnsharedAliasing</span></a> is <span class="d_keyword">false</span> for the <span class="inlinecode">Task</span>'s
    return type or the function the <span class="inlinecode">Task</span> executes is <span class="inlinecode">pure</span>.
    <span class="inlinecode">Task</span> objects that meet all other requirements specified in the
    <span class="inlinecode">@trusted</span> overloads of <span class="inlinecode">task</span> and <span class="inlinecode">scopedTask</span> may be created
    and executed from <span class="inlinecode">@safe</span> code via <span class="inlinecode">Task.executeInNewThread</span> but
    not via <span class="inlinecode">TaskPool</span>.
<br><br>

    While this function takes the address of variables that may
    be on the stack, some overloads are marked as @trusted.
    <span class="inlinecode">Task</span> includes a destructor that waits for the task to complete
    before destroying the stack frame it is allocated on.  Therefore,
    it is impossible for the stack frame to be destroyed before the task is
    complete and no longer referenced by a <span class="inlinecode">TaskPool</span>.<br><br>

</div>

<hr><div class="row-fluid declaration"><h3>@property @trusted bool <a class="symbol symbol-anchor" name="isDaemon" href="#isDaemon">isDaemon</a>();
<br>@property @trusted void <a class="symbol symbol-anchor" name="isDaemon" href="#isDaemon">isDaemon</a>(bool <i>newVal</i>);
</h3></div>

<div class="declaration-content"><p>These properties control whether the worker threads are daemon threads.
    A daemon thread is automatically terminated when all non-daemon threads
    have terminated.  A non-daemon thread will prevent a program from
    terminating as long as it has not terminated.
</p>

<p>If any <span class="inlinecode">TaskPool</span> with non-daemon threads is active, either <span class="inlinecode">stop</span>
    or <span class="inlinecode">finish</span> must be called on it before the program can terminate.
<br><br>

    The worker treads in the <span class="inlinecode">TaskPool</span> instance returned by the
    <span class="inlinecode">taskPool</span> property are daemon by default.  The worker threads of
    manually instantiated task pools are non-daemon by default.

</p>
<b>Note:</b><br>
For a size zero pool, the getter arbitrarily returns <span class="d_keyword">true</span> and the
           setter has no effect.<br><br>

</div>

<hr><div class="row-fluid declaration"><h3>@property @trusted int <a class="symbol symbol-anchor" name="priority" href="#priority">priority</a>();
<br>@property @trusted void <a class="symbol symbol-anchor" name="priority" href="#priority">priority</a>(int <i>newPriority</i>);
</h3></div>

<div class="declaration-content"><p>These functions allow getting and setting the OS scheduling <a class="symbol symbol-anchor" name="priority" href="#priority">priority</a> of
    the worker threads in this <span class="inlinecode">TaskPool</span>.  They forward to
    <span class="inlinecode">core.thread.Thread.<a class="symbol symbol-anchor" name="priority" href="#priority">priority</a></span>, so a given <a class="symbol symbol-anchor" name="priority" href="#priority">priority</a> value here means the
    same thing as an identical <a class="symbol symbol-anchor" name="priority" href="#priority">priority</a> value in <span class="inlinecode">core.thread</span>.
</p>

<b>Note:</b><br>
For a size zero pool, the getter arbitrarily returns
           <span class="inlinecode">core.thread.Thread.PRIORITY_MIN</span> and the setter has no effect.<br><br>

</div>

</div>
</div>

<hr><div class="row-fluid declaration"><h3>@property @trusted TaskPool <a class="symbol symbol-anchor" name="taskPool" href="#taskPool">taskPool</a>();
</h3></div>

<div class="declaration-content"><p>Returns a lazily initialized global instantiation of <span class="inlinecode">TaskPool</span>.
This function can safely be called concurrently from multiple non-worker
threads.  The worker threads in this pool are daemon threads, meaning that it
is not necessary to call <span class="inlinecode">TaskPool.stop</span> or <span class="inlinecode">TaskPool.finish</span> before
terminating the main thread.</p>


</div>

<hr><div class="row-fluid declaration"><h3>@property @trusted uint <a class="symbol symbol-anchor" name="defaultPoolThreads" href="#defaultPoolThreads">defaultPoolThreads</a>();
<br>@property @trusted void <a class="symbol symbol-anchor" name="defaultPoolThreads" href="#defaultPoolThreads">defaultPoolThreads</a>(uint <i>newVal</i>);
</h3></div>

<div class="declaration-content"><p>These properties get and set the number of worker threads in the <span class="inlinecode">TaskPool</span>
instance returned by <span class="inlinecode">taskPool</span>.  The default value is <span class="inlinecode">totalCPUs</span> - 1.
Calling the setter after the first call to <span class="inlinecode">taskPool</span> does not changes
number of worker threads in the instance returned by <span class="inlinecode">taskPool</span>.</p>


</div>

<hr><div class="row-fluid declaration"><h3>ParallelForeach!(R) <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a>(R)(R <i>range</i>);
<br>ParallelForeach!(R) <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a>(R)(R <i>range</i>, size_t <i>workUnitSize</i>);
</h3></div>

<div class="declaration-content"><p>Convenience functions that forwards to <span class="inlinecode">taskPool.<a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a></span>.  The
purpose of these is to make <a class="symbol symbol-anchor" name="parallel" href="#parallel">parallel</a> foreach less verbose and more
readable.
</p>

<b>Example:</b><br>
<pre class="d_code"><span class="d_comment">// Find the logarithm of every number from 1 to 1_000_000 in parallel,
</span>
<span class="d_comment">// using the default TaskPool instance.
</span>
<span class="d_keyword">auto</span> logs = <span class="d_keyword">new</span> <span class="d_keyword">double</span>[1_000_000];

<span class="d_keyword">foreach</span>(i, <span class="d_keyword">ref</span> elem; <u>parallel</u>(logs)) {
    elem = log(i + 1.0);
}
</pre>
<br><br>

</div>



				</div>
			</div>
			
			<hr>
			
			<div class="pull-right">
				<footer>
					<p>&copy; Copyright (c) 2009-2011, David Simcha.
 2012-2012</p>
				</footer>
			</div>
		</div>
	</div><!--/.fluid-container-->

	<!-- Bootstrap javascript
	================================================== -->
	<!-- Placed at the end of the document so the pages load faster -->
	<script src="bootDoc/assets/js/jquery.js"></script>
	<script src="bootDoc/assets/js/bootstrap-transition.js"></script>
	<script src="bootDoc/assets/js/bootstrap-alert.js"></script>
	<script src="bootDoc/assets/js/bootstrap-modal.js"></script>
	<script src="bootDoc/assets/js/bootstrap-dropdown.js"></script>
	<script src="bootDoc/assets/js/bootstrap-scrollspy.js"></script>
	<script src="bootDoc/assets/js/bootstrap-tab.js"></script>
	<script src="bootDoc/assets/js/bootstrap-tooltip.js"></script>
	<script src="bootDoc/assets/js/bootstrap-popover.js"></script>
	<script src="bootDoc/assets/js/bootstrap-button.js"></script>
	<script src="bootDoc/assets/js/bootstrap-collapse.js"></script>
	<script src="bootDoc/assets/js/bootstrap-carousel.js"></script>
	<script src="bootDoc/assets/js/bootstrap-typeahead.js"></script>
	
	<!-- bootDoc javascript
	================================================== -->
	<script src="bootDoc/bootdoc.js"></script>
	
	</body>
</html>

